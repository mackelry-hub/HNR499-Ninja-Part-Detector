{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCA8cKW7arQ",
        "outputId": "131442fa-169c-4679-899e-af992bcd693e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Flatten the 28×28 images into 784-length vectors\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "C = 10\n",
        "def one_hot(y, C):\n",
        "    Y = np.zeros((y.shape[0], C), dtype=np.float32)\n",
        "    Y[np.arange(y.shape[0]), y] = 1.0\n",
        "    return Y\n",
        "\n",
        "Y_train = one_hot(y_train, C)\n",
        "Y_test = one_hot(y_test, C)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First step is essentially reshaping data from 28 x 28 to a single vector of 784."
      ],
      "metadata": {
        "id": "w7ACaUwyI5KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and biases randomly (small values)\n",
        "rng = np.random.default_rng(42)\n",
        "W = rng.normal(0, 0.01, size=(28 * 28, C)).astype(np.float32)\n",
        "b = np.zeros((C,), dtype=np.float32)"
      ],
      "metadata": {
        "id": "VxDIKAok7dXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "W = weight matrix that transforms 784 input features into 10 output classes (guesses).\n",
        "\n",
        "\n",
        "b = bias vector added to each output.\n",
        "\n",
        "These values start random so the model can learn from scratch."
      ],
      "metadata": {
        "id": "QMvTkjMCJDAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax function: converts raw scores into probabilities\n",
        "def softmax(z):\n",
        "    z = z - z.max(axis=1, keepdims=True)  # numerical stability\n",
        "    expz = np.exp(z)\n",
        "    return expz / expz.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Forward pass\n",
        "def forward(X):\n",
        "    return softmax(X @ W + b)\n",
        "\n",
        "# Cross-entropy loss\n",
        "def cross_entropy(Y, P):\n",
        "    eps = 1e-12\n",
        "    return -np.mean(np.sum(Y * np.log(P + eps), axis=1))\n",
        "\n",
        "# Accuracy\n",
        "def accuracy(Y, P):\n",
        "    return np.mean(np.argmax(Y, axis=1) == np.argmax(P, axis=1))"
      ],
      "metadata": {
        "id": "eR-UYl997fZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax: Converts raw scores into probabilities, where the statistics come into data interpretation\n",
        "\n",
        "Forward Pass: Prediction = Input (X) * Weights (W) + bias (b)\n",
        "\n",
        "Cross Entropy Loss: Measures how far off predictions are off from true value: what we are trying to minimize"
      ],
      "metadata": {
        "id": "NUupJMuZJSEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "lr = 0.1\n",
        "batch = 256\n",
        "epochs = 8\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    idx = rng.permutation(x_train.shape[0])  # shuffle data\n",
        "    for i in range(0, len(idx), batch):\n",
        "        j = idx[i:i+batch]\n",
        "        Xb, Yb = x_train[j], Y_train[j]\n",
        "        Pb = forward(Xb)\n",
        "\n",
        "        # Gradient computation\n",
        "        grad_logits = (Pb - Yb) / Xb.shape[0]\n",
        "        gW = Xb.T @ grad_logits\n",
        "        gb = grad_logits.sum(axis=0)\n",
        "\n",
        "        # Weight update\n",
        "        W -= lr * gW\n",
        "        b -= lr * gb\n",
        "\n",
        "    # Monitor training progress\n",
        "    P = forward(x_train[:10000])\n",
        "    L = cross_entropy(Y_train[:10000], P)\n",
        "    A = accuracy(Y_train[:10000], P)\n",
        "    print(f\"Epoch {epoch+1:02d} — Loss: {L:.4f}, Accuracy: {A:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9JetUkq7gv3",
        "outputId": "5a736d2e-f450-4983-edcc-2054ff73be15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 — Loss: 0.4578, Accuracy: 0.8858\n",
            "Epoch 02 — Loss: 0.3865, Accuracy: 0.8969\n",
            "Epoch 03 — Loss: 0.3568, Accuracy: 0.9029\n",
            "Epoch 04 — Loss: 0.3398, Accuracy: 0.9070\n",
            "Epoch 05 — Loss: 0.3275, Accuracy: 0.9101\n",
            "Epoch 06 — Loss: 0.3183, Accuracy: 0.9123\n",
            "Epoch 07 — Loss: 0.3132, Accuracy: 0.9131\n",
            "Epoch 08 — Loss: 0.3065, Accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final test accuracy\n",
        "P_test = forward(x_test)\n",
        "test_acc = accuracy(Y_test, P_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzb9bKg87iGk",
        "outputId": "89051799-8e8e-457d-c09b-2aaebffab2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 91.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's New?: Every step, from forward pass to weight update, is done manually. Purely linear algebra and calculus.\n",
        "\n",
        "Much slower, but transparent and surprisingly accurate."
      ],
      "metadata": {
        "id": "_vpEAvno7i5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!jupyter nbconvert --to html '/content/drive/MyDrive/HNR499/HNR499_Model4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X775TxPE_LDt",
        "outputId": "751ebbed-ead5-4a5f-971f-60f3e4dcef40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}