{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m306P5gD8OKX",
        "outputId": "1e5dc5b3-b603-4c54-ece1-6fe09e94c595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load and flatten MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
        "x_test  = x_test.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "C = 10\n",
        "def one_hot(y, C):\n",
        "    Y = np.zeros((y.shape[0], C), dtype=np.float32)\n",
        "    Y[np.arange(y.shape[0]), y] = 1.0\n",
        "    return Y\n",
        "\n",
        "Y_train = one_hot(y_train, C)\n",
        "Y_test  = one_hot(y_test,  C)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "H = 128  # hidden layer size\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "# Xavier initialization\n",
        "W1 = rng.normal(0, 0.02, size=(28 * 28, H)).astype(np.float32)\n",
        "b1 = np.zeros((H,), dtype=np.float32)\n",
        "W2 = rng.normal(0, 0.02, size=(H, C)).astype(np.float32)\n",
        "b2 = np.zeros((C,), dtype=np.float32)"
      ],
      "metadata": {
        "id": "gWg0njAZ8Q8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduces \"Hidden Layer\" (H) used to learn more complex features. Now a two-layer neural network:\n",
        "\n",
        "Layer 1 learns features, Layer 2 uses those features to classify digits"
      ],
      "metadata": {
        "id": "jqpkAzirKFbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation and softmax\n",
        "def relu(u):\n",
        "    return np.maximum(u, 0.0)\n",
        "\n",
        "def softmax(z):\n",
        "    z = z - z.max(axis=1, keepdims=True)  # numerical stability\n",
        "    expz = np.exp(z)\n",
        "    return expz / expz.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Forward pass\n",
        "def forward(X):\n",
        "    u1 = X @ W1 + b1\n",
        "    h1 = relu(u1)\n",
        "    u2 = h1 @ W2 + b2\n",
        "    yhat = softmax(u2)\n",
        "    return yhat, (X, u1, h1, u2)\n",
        "\n",
        "# Accuracy\n",
        "def accuracy(Y, P):\n",
        "    return np.mean(np.argmax(Y, axis=1) == np.argmax(P, axis=1))"
      ],
      "metadata": {
        "id": "ZGhXEQsL8S9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "relu() introduces nonlinearity, allowing more complex decision surfaces.\n",
        "\n",
        "softmax() converts final scores to probabilities\n",
        "\n",
        "Forward pass:\n",
        "1. Linear transformation from input to hidden\n",
        "2. ReLU activation\n",
        "3. Linear transformation from hidden to output\n",
        "\n",
        "Intermediate results are used again during backpropogation"
      ],
      "metadata": {
        "id": "_Ks4LlT1KW0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(X, Y, lr=0.1, batch=128):\n",
        "    global W1, b1, W2, b2\n",
        "    idx = rng.permutation(X.shape[0])\n",
        "\n",
        "    for i in range(0, len(idx), batch):\n",
        "        j = idx[i:i+batch]\n",
        "        Xb, Yb = X[j], Y[j]\n",
        "\n",
        "        # Forward pass\n",
        "        yhat, (Xc, u1, h1, u2) = forward(Xb)\n",
        "\n",
        "        # Compute gradients step by step\n",
        "        du2 = (yhat - Yb) / Xb.shape[0]         # dL/du2 derivative of the loss w.r.t. output logits.\n",
        "        gW2 = h1.T @ du2                        # dL/dW2 gradient for output weights.\n",
        "        gb2 = du2.sum(axis=0)                   # dL/db2\n",
        "\n",
        "        dh1 = du2 @ W2.T                        # dL/dh1 gradient flowing backward into the hidden layer.\n",
        "        du1 = dh1 * (u1 > 0)                    # dL/du1 (ReLU derivative) (1 if >0, else 0).\n",
        "        gW1 = Xb.T @ du1                        # dL/dW1 gradient for first layer weights.\n",
        "        gb1 = du1.sum(axis=0)                   # dL/db1\n",
        "\n",
        "        # Gradient descent update\n",
        "        W2 -= lr * gW2\n",
        "        b2 -= lr * gb2\n",
        "        W1 -= lr * gW1\n",
        "        b1 -= lr * gb1\n",
        "\n",
        "# Train for several epochs\n",
        "epochs = 8\n",
        "for ep in range(epochs):\n",
        "    train_epoch(x_train, Y_train, lr=0.1, batch=128)\n",
        "    P = forward(x_train[:10000])[0]\n",
        "    acc = accuracy(Y_train[:10000], P)\n",
        "    print(f\"Epoch {ep+1:02d} — Training accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT9IVPp68UYa",
        "outputId": "22dc2070-fae4-4181-aa49-bea072556ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 — Training accuracy: 0.9092\n",
            "Epoch 02 — Training accuracy: 0.9270\n",
            "Epoch 03 — Training accuracy: 0.9388\n",
            "Epoch 04 — Training accuracy: 0.9466\n",
            "Epoch 05 — Training accuracy: 0.9544\n",
            "Epoch 06 — Training accuracy: 0.9592\n",
            "Epoch 07 — Training accuracy: 0.9628\n",
            "Epoch 08 — Training accuracy: 0.9674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "P_test = forward(x_test)[0]\n",
        "test_acc = accuracy(Y_test, P_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANB1oo3k8WL7",
        "outputId": "a3aa35a0-ecf2-4c8b-e1b8-c6b2a40d112d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes: Backpropogation is implemented entirely by hand, every derivative step is shown.\n",
        "\n",
        "No tensorFlow, no autograd, just matrix operations"
      ],
      "metadata": {
        "id": "q6kvvHc58dKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!jupyter nbconvert --to html '/content/drive/MyDrive/HNR499/HNR499_Model5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXPgfwLg_NBv",
        "outputId": "4c09d47d-7f8a-4ad5-ca6a-e5c1c2821b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/HNR499/HNR499_Model5 to html\n",
            "[NbConvertApp] Writing 293944 bytes to /content/drive/MyDrive/HNR499/HNR499_Model.html\n"
          ]
        }
      ]
    }
  ]
}